.
└── src
    ├── data_preprocessing
    │   ├── Lasry
    │   ├── Smillie
    │   └── vanGalen_Hourigan
    └── method_comparison
        ├── compare_algorithms
        │   ├── run_CellPhoneDB
        │   │   ├── build_customDB
        │   │   └── run_algorithm
        │   ├── run_community
        │   ├── run_NicheNet
        │   │   ├── build_customDB
        │   │   └── run_algorithm
        ├── compare_databases
        ├── compare_results
        └── resource_usage





2. Data Filtering
Notebook: ./$dataset/2.filtering.ipynb
Language: R
Tasks: This step involves additional refinement of the processed data, ensuring its quality and consistency for subsequent analysis. The filtering process includes:
Cell Filtering: Removes cells that appear in the count matrix but are absent in the cell annotation file.
Cell Type Filtering: Excludes cell types that do not meet the minimum prevalence criteria across samples, which may vary depending on the dataset characteristics.
Gene Filtering: Filters out genes based on their cumulative expression across cells, ensuring only genes with sufficient overall expression are retained for analysis.
Sample Filtering: Removes samples that fall below a certain threshold of cell type diversity, with specific criteria adjusted according to each dataset.
Output: The refined dataset is stored in .RData format, located at /results/data_preprocessing/$dataset/.



2. Data Filtering
Notebook: ./$dataset/2.filtering.ipynb
Language: R
Tasks: This stage focuses on refining the processed data by:
Cell Filtering: Removing cells that are not consistent between the count matrix and the cell annotation file.
Cell Type Filtering: Excluding cell types that are underrepresented in the dataset according to sample-specific criteria.
Gene Filtering: Discarding genes based on their expression profile across actual cells, targeting genes with minimal cumulative expression.
Sample Filtering: Omitting samples that do not meet the dataset-specific diversity criteria in terms of cell type representation.
Output: The filtered dataset is saved as .RData under /results/data_preprocessing/$dataset/.


3. Data Normalization
Notebook: ./$dataset/3.normalization.ipynb
Language: R, utilizing the Scran package [Insert Scran package link]
Input: Filtered data from the previous filtering step.
Output: [Describe any output produced, e.g., normalized expression matrices, if applicable. For Smillie, indicate if this is the output used for community. Note if Lasry data did not require this step and refer to Zenodo for downloadable files.]


4. Batch Correction
Notebook: ./$dataset/4.1.batch_correction.ipynb
Language: Python, employing the scgen library [Insert scgen library link]
Input: Normalized data from the normalization step.
Warning: Batch correction is computationally intensive, with significant processing time required.
Output: [Detail any output files here, e.g., batch-corrected data files. For Cangalen-Oetjen, specify if this is the output for community. Confirm and clarify the use of batch correction for Smillie and Lasry datasets, especially in relation to visualization and community analysis.]


5. Data Visualization
Notebook: ./$dataset/4.2.visualization.ipynb
Language: R
Tasks: This notebook is used to visualize the processed data, which helps in understanding the effects of the preprocessing steps on the data quality and structure.
To complete these sections, please make sure to:

Replace [Insert Scran package link] and [Insert scgen library link] with the actual URLs.
Provide the specific output details for normalization and batch correction steps as required.
Verify the use of batch correction for each dataset and explain its purpose clearly.
Include the link to Zenodo or any other data repository where users can access the datasets.
For the summary about the files passed to community:

Data Integration with Community
The processed and curated files ready for community analysis adhere to a structured format. Essential columns such as gene_name, cell_type, and expression_value are consistently labeled across all datasets. This standardization ensures compatibility with the community tool, facilitating seamless integration and analysis. Users can find the detailed structure of these files and instructions on how to use them within the community framework in the Community Repository.



Normalized expression matrices. Simillie dataset does not need further pre-processing step and the output from this step is used as an input to the tools. Lasry dataset was already normalized, thus we use the filtered count matrix from the previous step. On the other hand VanGalen-Oetjen dataset requires a batch correction, so we do a batch correction for this dataset in the next step.  



3. Data Normalization
Notebook: ./$dataset/3.normalization.ipynb
Language: R, utilizing the Scran package [Insert Scran package link here]
Input: Filtered data from the previous filtering step.
Output: The output includes normalized expression matrices. For the Smillie dataset, this normalized data is directly used as input for analysis with the community tool, as no further preprocessing is required. The Lasry dataset comes pre-normalized; therefore, the filtered count matrix from the previous step is used. Downloadable files can be found on Zenodo [Insert Zenodo link here].



4. Batch Correction
Notebook: ./$dataset/4.1.batch_correction.ipynb
Language: Python, employing the scgen library [Insert scgen library link here]
Input: Normalized data from the normalization step.
Warning: This step is computationally intensive and may require approximately 14 hours on a system with 128GB RAM and 30 CPUs. GPU acceleration is recommended for efficiency.
Output: For the VanGalen-Oetjen dataset, this step is crucial, and the batch-corrected output is then used as input for the community tool. Batch correction is not performed for the Smillie dataset, as it does not require this step. The Lasry dataset also bypasses this step since it was already normalized. All batch-corrected files can be downloaded from Zenodo [Insert Zenodo link here].



SRC*********  ***********************



1. Data Processing
The data_processing section details the procedures applied to the published raw datasets from Lasry and Simillie. Our pipeline is structured into detailed steps, enhancing data quality and usability for downstream analysis:

Initial Cleaning: This foundational step deals with the preliminary cleaning and formatting of the raw data to facilitate further processing stages.

Filtering: The filtering phase is comprehensive, encompassing:

Cell presence validation by reconciling the count matrix with the cell annotation file.
Cell type exclusion based on representation thresholds that are dataset-specific.
Gene exclusion for those with minimal cumulative expression across cells.
Sample exclusion if they do not meet the dataset-specific criteria for cell type diversity.
Normalization: Utilizing the Scran package [Insert link to Scran publication], normalization is performed to adjust for cell-type intrinsic differences in total RNA levels. This step is applied consistently across all datasets unless otherwise specified.

Batch Correction (VanGalen-Oetjen only): To correct for batch effects in the VanGalen-Oetjen dataset, we employ [Insert batch correction method and link to publication]. This ensures comparability across different batches of data.

UMAP Visualization: Post-processing, the UMAP algorithm is employed to visualize the high-dimensional data in a two-dimensional space, providing an intuitive representation of the dataset's structure.


Cell Presence Validation: Ensuring consistency between the count matrix and cell annotation file to confirm the presence of all listed cells.


*******************************

2. Method Comparison

The method_comparison section conducts an in-depth analysis using the Lasry dataset for comparing cell communication results and to evaluate resource usage and adaptability to varying data sizes, we used 3 datasets, namely Lasry, Smillie and Integrated VanGalen-Oetjen dataset by subsampling accross a range from 6 to 32 scRNAseq samples

This section includes:

compare_databases: Here, we explore and compare the original ligand-receptor databases as provided by each cell communication tool. The objective is to assess the variances and commonalities between the databases that form the backbone of each tool's analysis.

compare_cell_communication_results: This directory is systematically arranged into sub-directories for each tool:

run_xxx: Contains the process of creating a unified ligand-receptor database, derived from the community database, which is then used to analyze cell communication with tool XXX.
run_yyy: Follows the same procedure as run_xxx, tailored for tool YYY.
run_zzz: Mirrors the aforementioned directories, adapting the unified database approach for tool ZZZ.
Each run directory details the steps taken to ensure that all tools are compared under standardized conditions, allowing for a fair assessment of their performance.

compare_results: The notebooks within this directory are dedicated to the visualization and comprehensive analysis of the results obtained from each communication tool. This comparative analysis is critical for determining the efficacy and accuracy of each tool in elucidating cell-cell communication dynamics.



DATABASE (BASED ON THE COMMUNITY DATABASE) TO COMPARE THE PERFORMANCE OF THE TOOLS UNDER STANDARDIZED CONDITIONS, AS WELL AS THE COMMUNICATION ANALYSIS BY EACH TOOL.




The method_comparison section is meticulously organized to evaluate different aspects of cell communication analysis tools using specific datasets:

Dataset for Comparison of Cell Communication Results: The Lasry dataset serves as the primary resource for comparing the cell communication results generated by different tools. This dataset provides a robust platform for analyzing the effectiveness and accuracy of each tool in interpreting cell-cell communication.

Resource Usage and Adaptability Analysis: To assess the scalability and efficiency of the tools, we employ three distinct datasets: Lasry, Smillie, and an integrated VanGalen-Oetjen dataset. The evaluation involves subsampling these datasets across a range from 6 to 32 single-cell RNAseq samples. This approach allows us to test how well each tool adapts to different data sizes and complexities.

The section includes:

compare_databases: In this directory, notebooks are dedicated to comparing the original ligand-receptor databases provided by each tool. This comparison is crucial to understand the foundational differences and similarities that may influence the tool's analysis output.

compare_cell_communication_results: This part is further divided into subdirectories for detailed analysis:

run_lasry, run_smillie, run_vangalen-oetjen: Each directory contains steps for constructing a unified ligand-receptor database based on the community database. This unified approach is then applied to analyze cell communication using the respective datasets, ensuring a standardized comparison across different tools.
compare_results: Notebooks here focus on visualizing and analyzing the outputs from each tool, offering a comprehensive look at how different tools perform in various aspects of cell communication analysis.



*****************************





*************

Data Preprocessing Steps
Data Source and Selection:

The analysis focused on AML cohort samples collected at diagnosis.
Excluded duplicated samples from healthy individuals `healthy-4` and `healthy-5`. This resulted in a dataset of 14 samples, comprising both the healthy and AML cohorts, which serve as the input for the preprocessing pipeline. Additionally, genes with all-zero values were removed, resulting 31,843 genes. 
Gene Filtering:

Initially, genes with all-zero values were removed, followed by the exclusion of weakly expressed genes. (Clarify if 31,843 genes is the final number post all filtering steps or only after zero-value gene removal).
Cell Filtering:

Cells were filtered based on library size (between 1,100 and 30,000 reads) and gene expression (more than 500 expressed genes).
This filtering resulted in 57,420 cells remaining in the dataset.
Cell Type Filtering:

Cell subtypes were grouped into 11 larger classes: HSPC, monocytes, granulocytes, DC, erythrocytes, megakaryocytes, perivascular cells, lymphoid progenitor cells (lymP), B-cells, T-cells, and NK cells. (Include link to the cell relabelling table).

Cell types with at least 5 cells per sample and presence in at least 12 samples were considered. Megakaryocytes, Perivascular cells, lymP cells, Natural killer, Dendritic cells, were excluded as they did not meet these criteria. 


This resulted in 8 cell types and 56,662 total cells being retained for analysis.



Genes filter: Psuedo-bulk cells types were constructed (per sample) and filtered out genes that have too low cumulative expression in these pseudo-bulks. 